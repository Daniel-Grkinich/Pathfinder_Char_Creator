{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString, Tag\n",
    "import requests\n",
    "import re\n",
    "\n",
    "url = 'https://www.aonprd.com/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ArchivesNethysScraper:\n",
    "    def __init__(self, url, class_name):\n",
    "        self.url = url\n",
    "        self.href = f'ClassDisplay.aspx?ItemName={class_name}'\n",
    "        self.page = requests.get(url + self.href)\n",
    "        self.soup = BeautifulSoup(self.page.content, 'html.parser')\n",
    "        self.table = self.soup.find(\"table\")\n",
    "\n",
    "    def table_rows(self):\n",
    "        for b in self.soup.find_all('b')[1:]:\n",
    "            yield b\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        # Replace Unicode right single quotation mark with an apostrophe\n",
    "        cleaned_text = [line.replace('\\u2019', \"'\").replace('\\u2018', \"'\").replace('\\u201c', '\"').replace('\\u201d', '\"').strip() for line in text if line.strip() and line.strip() != \".\"]\n",
    "        return ' '.join(cleaned_text)\n",
    "    \n",
    "    def remove_parenthesis(self, input_string):\n",
    "        pattern = r\"\\(.*?pg\\..*?\\)\"\n",
    "        result = re.sub(pattern, '', input_string)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def get_class_info(self, table_row):\n",
    "        # print(f'This is the href {self.href}')\n",
    "        output = {}\n",
    "        b_tags = self.soup.find_all('b')\n",
    "\n",
    "        for i, b_tag in enumerate(b_tags):\n",
    "            key = b_tag.text.lower()\n",
    "            # Extract all navigable strings until the next <b> tag\n",
    "            value_tags = []\n",
    "            next_sibling = b_tag.next_sibling\n",
    "\n",
    "\n",
    "            while next_sibling and next_sibling.name != 'b':\n",
    "                if hasattr(next_sibling, 'strings'):\n",
    "                    # Join all strings to handle multiple lines\n",
    "                    value_tags.append(' '.join(next_sibling.strings).strip())\n",
    "\n",
    "                next_sibling = next_sibling.next_sibling\n",
    "\n",
    "            cleaned_value = self.clean_text(value_tags)\n",
    "            cleaned_value = self.remove_parenthesis(cleaned_value)\n",
    "            output[key] = cleaned_value\n",
    "\n",
    "        return output            \n",
    "\n",
    "import json\n",
    "\n",
    "class_names = [\"Alchemist\", \"Antipaladin\", \"Arcanist\", \"Barbarian\", \"Barbarian (Unchained)\", \"Bard\", \"Bloodrager\", \"Brawler\", \"Cavalier\", \"Cleric\", \"Druid\", \"Fighter\", \"Gunslinger\", \"Hunter\", \"Inquisitor\", \"Investigator\", \"Kineticist\", \"Magus\", \"Medium\", \"Mesmerist\", \"Monk\", \"Monk (Unchained)\", \"Ninja\", \"Occultist\", \"Oracle\", \"Paladin\", \"Psychic\", \"Ranger\", \"Rogue\", \"Rogue (Unchained)\", \"Samurai\", \"Shaman\", \"Shifter\", \"Skald\", \"Slayer\", \"Sorcerer\", \"Spiritualist\", \"Summoner\", \"Summoner (Unchained)\", \"Swashbuckler\", \"Vigilante\", \"Warpriest\", \"Witch\", \"Wizard\"]\n",
    "\n",
    "\n",
    "json_output = '{' + ',\\n'.join([\n",
    "    f'  \"{c}\": {json.dumps({k: v for k, v in ArchivesNethysScraper(url, c).get_class_info(next(ArchivesNethysScraper(url, c).table_rows(), None).string).items() if v}, indent=2)}'\n",
    "    for c in class_names\n",
    "]) + '\\n}'\n",
    "\n",
    "print(json_output)\n",
    " \n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
