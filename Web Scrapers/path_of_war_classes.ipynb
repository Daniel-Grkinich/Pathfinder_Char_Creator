{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString, Tag\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "url = 'https://libraryofmetzofitz.fandom.com/wiki/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ArchivesNethysScraper:\n",
    "    def __init__(self, url, class_name):\n",
    "        self.url = url\n",
    "        self.href = f'{class_name}'\n",
    "        self.page = requests.get(url + self.href)\n",
    "        self.soup = BeautifulSoup(self.page.content, 'html.parser')\n",
    "        self.table = self.soup.find(\"table\")\n",
    "\n",
    "    def table_rows(self):\n",
    "        for b in self.soup.find_all('b')[1:]:\n",
    "            yield b\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        # Replace Unicode right single quotation mark with an apostrophe\n",
    "        cleaned_text = [line.replace('\\u2019', \"'\").replace('\\u2018', \"'\").replace('\\u201c', '\"').replace('\\u201d', '\"').strip() for line in text if line.strip() and line.strip() != \".\"]\n",
    "        return ' '.join(cleaned_text)\n",
    "    \n",
    "    def remove_parenthesis(self, input_string):\n",
    "        pattern = r\"\\(.*?pg\\..*?\\)\"\n",
    "        result = re.sub(pattern, '', input_string)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def get_class_info(self, table_row):\n",
    "        output = {}\n",
    "        # Find all h3 and b tags\n",
    "        tags = self.soup.find_all(['h3', 'b'])\n",
    "\n",
    "        # Iterate over each tag\n",
    "        for tag in tags:\n",
    "            # Extract tag text and convert to lowercase as key\n",
    "            key = tag.text.lower()\n",
    "            # Extract all navigable strings until the next h3 or b tag\n",
    "            value_tags = []\n",
    "            next_sibling = tag.next_sibling\n",
    "\n",
    "            while next_sibling and (not isinstance(next_sibling, Tag) or next_sibling.name not in ['h3', 'b']):\n",
    "                if hasattr(next_sibling, 'strings'):\n",
    "                    # Join all strings to handle multiple lines\n",
    "                    value_tags.append(' '.join(next_sibling.strings).strip())\n",
    "\n",
    "                next_sibling = next_sibling.next_sibling\n",
    "\n",
    "            # Clean the extracted value\n",
    "            cleaned_value = self.clean_text(value_tags)\n",
    "            cleaned_value = self.remove_parenthesis(cleaned_value)\n",
    "            output[key] = cleaned_value\n",
    "\n",
    "        return output\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "def get_class_info_json(url, class_name):\n",
    "    scraper = ArchivesNethysScraper(url, class_name)\n",
    "    class_info = scraper.get_class_info(next(scraper.table_rows(), None).string)\n",
    "    filtered_info = {k: v for k, v in class_info.items() if v}\n",
    "    return json.dumps(filtered_info, indent=2)\n",
    "\n",
    "class_names = [\"Harbinger\", \"Mystic\", \"Stalker\", \"Warder\", \"Warlord\", \"Zealot\"]\n",
    "\n",
    "json_output = '{\\n' + ',\\n'.join([\n",
    "    f'  \"{class_name}\": {get_class_info_json(url, class_name)}'\n",
    "    for class_name in class_names\n",
    "]) + '\\n}'\n",
    "\n",
    "print(json_output)\n",
    " \n",
    "\n",
    "import json\n",
    "\n",
    "def get_class_info_json(url, class_name):\n",
    "    scraper = ArchivesNethysScraper(url, class_name)\n",
    "    class_info = scraper.get_class_info(next(scraper.table_rows(), None).string)\n",
    "    filtered_info = {k: v for k, v in class_info.items() if v}\n",
    "    return filtered_info\n",
    "\n",
    "class_names = [\"Harbinger\", \"Mystic\", \"Stalker\", \"Warder\", \"Warlord\", \"Zealot\"]\n",
    "\n",
    "# Create a dictionary to store class information\n",
    "class_info_dict = {}\n",
    "for class_name in class_names:\n",
    "    class_info_dict[class_name] = get_class_info_json(url, class_name)\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('path_of_war_bad.json', 'w') as json_file:\n",
    "    json.dump(class_info_dict, json_file, indent=2)\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
