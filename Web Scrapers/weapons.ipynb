{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://www.aonprd.com/'\n",
    "\n",
    "class ArchetypeScraper:\n",
    "    def __init__(self, url, class_name):\n",
    "        self.url = url \n",
    "        self.href = f'EquipmentWeapons.aspx?Proficiency={class_name}'\n",
    "        self.page = requests.get(url + self.href)\n",
    "        self.soup = BeautifulSoup(self.page.content, 'html.parser')\n",
    "        self.tables = self.soup.find(\"table\")\n",
    "        self.table = self.soup.find_all(\"table\")\n",
    "\n",
    "    def table_rows(self):\n",
    "        # we changed this, to look for all tables, since the weapons data was help in multiple tables rather than one big table like the rest of the data\n",
    "        for table in self.soup.find_all('table'):\n",
    "            for tr in table.find_all('tr')[1:]:\n",
    "                yield tr\n",
    "\n",
    "    def archetype_name(self, href2_list):\n",
    "        for url in href2_list:\n",
    "            values = url.split('=')[1]\n",
    "            #url has the class name + the archetype name, we need to remove the class name manually\n",
    "            value = values.replace(f'{class_name} ', '')\n",
    "            return value            \n",
    "\n",
    "    def clean_text(self, text):\n",
    "        # Replace Unicode right single quotation mark with an apostrophe\n",
    "        cleaned_text = [line.replace('\\u2019', \"'\").strip() for line in text if line.strip() and line.strip() != \".\"]\n",
    "        return ' '.join(cleaned_text)\n",
    "\n",
    "    def get_archetype_info(self, table_row):\n",
    "        output = {}\n",
    "        tag = table_row.td\n",
    "        \n",
    "        print(tag)\n",
    "        href2 = None\n",
    "\n",
    "        try:\n",
    "            # Attempt to access the 'href' attribute\n",
    "            href2 = tag.a.attrs['href']\n",
    "        except AttributeError as e:\n",
    "            print(f\"AttributeError: {e}\")\n",
    "            # Handle the exception\n",
    "        except TypeError as e:\n",
    "            print(f\"KeyError: {e}\")\n",
    "            # Handle the exception\n",
    "\n",
    "        href2_list = []\n",
    "        # Check if href2 is not None before appending\n",
    "        if href2 is not None:\n",
    "            href2_list.append(href2)\n",
    "\n",
    "        value = self.archetype_name(href2_list)\n",
    "\n",
    "        # print(tag)\n",
    "        if href2 != None:\n",
    "            detail_page = requests.get(self.url + href2)\n",
    "            detail_soup = BeautifulSoup(detail_page.content, 'html.parser')\n",
    "\n",
    "            # Find all <b> tags on the detail page\n",
    "            b_tags = detail_soup.find_all('b')\n",
    "\n",
    "            for i, b_tag in enumerate(b_tags):\n",
    "                key = b_tag.text.lower()\n",
    "\n",
    "                # Extract all navigable strings until the next <b> tag\n",
    "                value_tags = []\n",
    "                next_sibling = b_tag.next_sibling\n",
    "\n",
    "\n",
    "                while next_sibling and next_sibling.name != 'b':\n",
    "                    if hasattr(next_sibling, 'strings'):\n",
    "                        # Join all strings to handle multiple lines\n",
    "                        value_tags.append(' '.join(next_sibling.strings).strip())\n",
    "\n",
    "                    next_sibling = next_sibling.next_sibling\n",
    "\n",
    "                cleaned_value = self.clean_text(value_tags)\n",
    "                output[key] = cleaned_value\n",
    "\n",
    "            return value, output\n",
    "        else:\n",
    "            print(f'No href found for {value}')\n",
    "\n",
    "# List of class names\n",
    "class_names = [\"Simple\", \"Martial\", \"Exotic\", \"Ammunition\", \"Firearm\", \"Mod\", \"Siege\", \"Special\"]\n",
    "\n",
    "# Create a dictionary to store the JSON output for each class\n",
    "json_output = {}\n",
    "\n",
    "# Iterate through class names and scrape archetype information\n",
    "for class_name in class_names:\n",
    "    arch_scraper = ArchetypeScraper(url, class_name)\n",
    "\n",
    "    # Create a list to store information for all archetypes of the current class\n",
    "    archetypes_info = {}\n",
    "\n",
    "    # Iterate through all table rows and collect information for each archetype\n",
    "    for table_row in arch_scraper.table_rows():\n",
    "        i = 0\n",
    "        archetype_name, archetype_info = arch_scraper.get_archetype_info(table_row)\n",
    "        archetypes_info[archetype_name] = archetype_info\n",
    "        i+=1\n",
    "    # Add the dictionary of archetypes' information to the json_output dictionary\n",
    "    json_output[class_name] = archetypes_info\n",
    "\n",
    "# Convert the dictionary to a JSON-formatted string\n",
    "json_string = json.dumps(json_output, indent=2)\n",
    "\n",
    "with open('Firearm.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(json_output, json_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Print the JSON string\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
